{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce178b9",
   "metadata": {},
   "source": [
    "# NIRSpec IFU Data Reduction Pipeline\n",
    "\n",
    "By the JWST ERS TEMPLATES team (B. Welch, +). \n",
    "Early draft version, Sept. 2022. \n",
    "\n",
    "Based on a combination of notebooks from STSCI:  \n",
    "https://github.com/STScI-MIRI/MRS-ExampleNB/blob/main/Flight_Notebook1/MRS_FlightNB1.ipynb\n",
    "https://github.com/spacetelescope/jwebbinar_prep/blob/main/spec_mode/spec_mode_stage_2.ipynb\n",
    "https://github.com/spacetelescope/jwebbinar_prep/blob/main/spec_mode/spec_mode_stage_3.ipynb\n",
    "https://github.com/spacetelescope/jwebbinar_prep/blob/main/ifu_session/jwebbinar5_nirspecifu.ipynb\n",
    "\n",
    "Prerequisites: Install JWST pipeline. See TEMPLATES pipeline installation notebook (https://github.com/JWST-Templates/Notebooks/blob/main/0_install_pipeline.ipynb) for help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb0ad5",
   "metadata": {},
   "source": [
    "# Example Pipeline Run on NIRSpec IFU Data\n",
    "Currently this is the re-observed IFU data on SDSS-1723.\n",
    "There is a lot of work still to do before we fully understand the best practices for running this pipeline. For a while this notebook will contain a lot of trial and error. It may be a bit ugly, but hopefully it is useful!\n",
    "\n",
    "### Note!\n",
    "This version is applying background subtraction in the Stage 3 pipeline. It takes the Stage 2 output extracted 1-D spectra (\"x1d.fits\") from the background observations, and creates an average spectrum to universally subtract from the science data. \n",
    "\n",
    "There is another possibility for background subtraction, where the dedicated background exposures would be subtracted from the science exposures during the Stage 2 pipeline. These would be \"image from image\" subtractions, rather than creating a universal background spectrum. I'm planning to work up a version of this kind of background subtraction soon. \n",
    "\n",
    "It's not clear which method is going to perform the best, so we're finding out! \n",
    "\n",
    "\n",
    "#### ---- note from TAH:  \n",
    "the installation notebook in this repo specifies a different CDRS_PATH definition, which is fine although perhaps for the skae of the users of these notebooks we should make that path definition the same as used in this notebook? or vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d09de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Modify the paths to the relevant directories on your machine\n",
    "# ------------------------------------------------------------\n",
    "# 1) point to where the jwst pipeline config files are located\n",
    "#home = \"/Users/bdwelch1/Documents/\" # for B. Welch\n",
    "home = \"/Users/tahutch1/programs/jwst-drp/\" # for T. Hutchison\n",
    "\n",
    "# 2) point to where you keep your data\n",
    "# input_path = '/Users/bdwelch1/Documents/data/templates/sdss1723/retake_filegrab_take2/JWST/' # for B. Welch\n",
    "input_path = \"/Users/tahutch1/data/raw/jwst/ers/templates/MAST_2022-09-23T1410/JWST/\" # for T. Hutchison\n",
    "\n",
    "# 3) point to where you want your processed outputs to live\n",
    "# output_path = '/Users/bdwelch1/Documents/data/templates/sdss1723/pipeline_testrun_take2/' # for B. Welch\n",
    "output_path = \"/Users/tahutch1/data/raw/jwst/ers/templates/reduced/\" # for T. Hutchison\n",
    "\n",
    "\n",
    "###############################################\n",
    "# IMPORTANT!! Make sure to use 'jwst-crds-pub'! \n",
    "# This will contain the most up to date reference files\n",
    "###############################################\n",
    "os.environ[\"CRDS_PATH\"] = home + \"crds_cache/jwst_pub\"\n",
    "os.environ[\"CRDS_SERVER_URL\"] = \"https://jwst-crds-pub.stsci.edu\"\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "import json\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "import astropy.units as u\n",
    "from astropy import wcs\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch, LinearStretch, AsinhStretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a190058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54df3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calwebb_spec and spec3 pipelines\n",
    "from jwst.pipeline import Spec2Pipeline\n",
    "from jwst.pipeline import Spec3Pipeline\n",
    "\n",
    "# the level1 pipeline:\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "\n",
    "# individual steps - probably remove this later, running step-by-step is kind of a pain\n",
    "from jwst.assign_wcs import AssignWcsStep\n",
    "from jwst.assign_wcs import nirspec\n",
    "from jwst.background import BackgroundStep\n",
    "from jwst.imprint import ImprintStep\n",
    "from jwst.msaflagopen import MSAFlagOpenStep\n",
    "from jwst.extract_2d import Extract2dStep\n",
    "from jwst.srctype import SourceTypeStep\n",
    "from jwst.wavecorr import WavecorrStep\n",
    "from jwst.flatfield import FlatFieldStep\n",
    "from jwst.pathloss import PathLossStep\n",
    "from jwst.photom import PhotomStep\n",
    "from jwst.cube_build import CubeBuildStep\n",
    "from jwst.extract_1d import Extract1dStep\n",
    "\n",
    "# data models\n",
    "from jwst import datamodels\n",
    "\n",
    "# association file utilities\n",
    "from jwst.associations import asn_from_list as afl # Tools for creating association files\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase # Definition of a Lvl2 association file\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base # Definition of a Lvl3 association file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaea6ff5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copied over from JWebbinars notebooks. I don't really use it here, so can probably be deleted?\n",
    "def show_image(data_2d, vmin, vmax, xsize=15, ysize=15, title=None, aspect=1, scale='log', units='MJy/sr'):\n",
    "    \"\"\"Function to generate a 2D, log-scaled image of the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray\n",
    "        2D image to be displayed\n",
    "        \n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "        \n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "        \n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "        \n",
    "    scale : str\n",
    "        Specify scaling of the image. Can be 'log' or 'linear'\n",
    "        \n",
    "    units : str\n",
    "        Units of the data. Used for the annotation in the\n",
    "        color bar\n",
    "    \"\"\"\n",
    "    if scale == 'log':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LogStretch())\n",
    "    elif scale == 'linear':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=LinearStretch())\n",
    "    elif scale == 'Asinh':\n",
    "        norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                              stretch=AsinhStretch())\n",
    "    fig = plt.figure(figsize=(xsize, ysize))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm, aspect=aspect, cmap='gist_earth')\n",
    "\n",
    "    fig.colorbar(im, label=units)\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    if title:\n",
    "        plt.title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3b416",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stage 1 - Detector-level processing\n",
    "The first time this runs it will be glacially slow, as many GB of reference files need to be downloaded.\n",
    "Changing the maximum_cores variable in the parameter file can speed up this step. The default is \"None\", which uses one core. Other options are \"quarter\", \"half\", and \"all\", which will use 1/4, 1/2, or all available cores respectively.\n",
    "\n",
    "Currently the cell below processes all uncal.fits files together, but I need to change this. Later we want the \"science\" and \"background\" exposures to be treated seperately. I moved files over to different sub-directories manually for this run, but it will be far easier to just set this up from the start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40cb000-c5dd-44d5-a9d1-1a98304e9970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IFU: 64, Number of sky: 55\n"
     ]
    }
   ],
   "source": [
    "# test by TAH to see if the files are accessible\n",
    "files = glob.glob(input_path + '*nrs*/*_uncal.fits') #list the uncalibrated (level 1b) files.\n",
    "files = sorted(files)\n",
    "\n",
    "ifu,sky = 0,0\n",
    "\n",
    "for exposure in files:\n",
    "    test = fits.open(exposure)\n",
    "    head = test[0].header\n",
    "    if head['TARGPROP'] == 'SGAS1723-IFU': ifu+=1\n",
    "    elif head['TARGPROP'] == 'SGAS1723-SKY': sky+=1\n",
    "    else: print('not target')\n",
    "    \n",
    "print(f'Number of IFU: {ifu}, Number of sky: {sky}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f30ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 18:22:28,854 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.extensions plugin from package asdf-astropy==0.2.2 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:28,873 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.extensions plugin from package gwcs==0.18.2 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,007 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.extensions plugin from package jwst==1.7.2 failed to load:\n",
      "\n",
      "VersionConflict: (certifi 2022.9.24 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('certifi==2022.5.18.1'))\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,035 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf_extensions plugin from package jwst==1.7.2 failed to load:\n",
      "\n",
      "VersionConflict: (certifi 2022.9.24 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('certifi==2022.5.18.1'))\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,060 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf_extensions plugin from package stpipe==0.4.2 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,061 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf_extensions plugin from package asdf==2.13.0 failed to load:\n",
      "\n",
      "VersionConflict: (jsonschema 4.16.0 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'))\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,064 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package asdf-astropy==0.2.2 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,065 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package asdf-coordinates-schemas==0.1.0 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,074 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package asdf-wcs-schemas==0.1.1 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,076 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package jwst==1.7.2 failed to load:\n",
      "\n",
      "VersionConflict: (certifi 2022.9.24 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('certifi==2022.5.18.1'))\n",
      "  warnings.warn(\n",
      "\n",
      "2022-09-28 18:22:29,077 - stpipe - WARNING - /Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package asdf==2.13.0 failed to load:\n",
      "\n",
      "VersionConflict: (jsonschema 4.16.0 (/Users/tahutch1/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'))\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to fetch schema from non-file URL: http://stsci.edu/schemas/jwst_datamodel/level1b.schema",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(files)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exposure \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m----> 6\u001b[0m     Detector1Pipeline\u001b[38;5;241m.\u001b[39mcall(exposure,\u001b[38;5;66;03m#config_file=detector1_parameter_file, maximum_cores=5,\\\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                            output_dir\u001b[38;5;241m=\u001b[39moutput_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2a/\u001b[39m\u001b[38;5;124m'\u001b[39m,\\\n\u001b[1;32m      8\u001b[0m                            output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(exposure)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m11\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/stpipe/step.py:644\u001b[0m, in \u001b[0;36mStep.call\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    643\u001b[0m     filename \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 644\u001b[0m config, config_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/stpipe/step.py:1379\u001b[0m, in \u001b[0;36mStep.build_config\u001b[0;34m(cls, input, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m log_cls \u001b[38;5;241m=\u001b[39m log\u001b[38;5;241m.\u001b[39mgetLogger(logger_name)\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[0;32m-> 1379\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_from_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1381\u001b[0m     log_cls\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo filename given, cannot retrieve config from CRDS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/stpipe/pipeline.py:185\u001b[0m, in \u001b[0;36mPipeline.get_config_from_reference\u001b[0;34m(cls, dataset, disable, crds_observatory)\u001b[0m\n\u001b[1;32m    182\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieving all substep parameters from CRDS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Iterate over the steps in the pipeline\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datamodels_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masn_n_members\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m model:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Sequence):\n\u001b[1;32m    187\u001b[0m         crds_parameters \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_models[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_crds_parameters()\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/jwst/stpipe/core.py:28\u001b[0m, in \u001b[0;36mJwstStep._datamodels_open\u001b[0;34m(cls, init, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_datamodels_open\u001b[39m(\u001b[38;5;28mcls\u001b[39m, init, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatamodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/jwst/datamodels/util.py:217\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(init, guess, memmap, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpening as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Actually open the model\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mnew_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Close the hdulist if we opened it\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_to_close \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# TODO: We need a better solution than messing with DataModel\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# internals.\u001b[39;00m\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/stdatamodels/model_base.py:174\u001b[0m, in \u001b[0;36mDataModel.__init__\u001b[0;34m(self, init, schema, memmap, pass_invalid_values, strict_validation, validate_on_assignment, cast_fits_arrays, validate_arrays, ignore_missing_extensions, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         schema \u001b[38;5;241m=\u001b[39m _DEFAULT_SCHEMA\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;66;03m# Create an AsdfFile so we can use its resolver for loading schemas\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[43masdf_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_references\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema \u001b[38;5;241m=\u001b[39m mschema\u001b[38;5;241m.\u001b[39mmerge_property_trees(schema)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Provide the object as context to other classes and functions\u001b[39;00m\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/schema.py:431\u001b[0m, in \u001b[0;36mload_schema\u001b[0;34m(url, resolver, resolve_references, resolve_local_refs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     resolver \u001b[38;5;241m=\u001b[39m extension\u001b[38;5;241m.\u001b[39mget_default_resolver()\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# We want to cache the work that went into constructing the schema, but returning\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# the same object is treacherous, because users who mutate the result will not\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# expect that they're changing the schema everywhere.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[43m_load_schema_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_references\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_local_refs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/schema.py:478\u001b[0m, in \u001b[0;36m_load_schema_cached\u001b[0;34m(url, resolver, resolve_references, resolve_local_refs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_schema_cached\u001b[39m(url, resolver, resolve_references, resolve_local_refs):\n\u001b[1;32m    477\u001b[0m     loader \u001b[38;5;241m=\u001b[39m _make_schema_loader(resolver)\n\u001b[0;32m--> 478\u001b[0m     schema, url \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolve_references \u001b[38;5;129;01mor\u001b[39;00m resolve_local_refs:\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve_refs\u001b[39m(node, json_id):\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/schema.py:355\u001b[0m, in \u001b[0;36m_make_schema_loader.<locals>.load_schema\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, url\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# If not, this must be a URL (or missing).  Fall back to fetching\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# the schema the old way:\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programs/anaconda3/envs/jwst-test/lib/python3.10/site-packages/asdf/schema.py:319\u001b[0m, in \u001b[0;36m_load_schema\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_schema\u001b[39m(url):\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masdf://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to fetch schema from non-file URL: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url)\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m generic_io\u001b[38;5;241m.\u001b[39mget_file(url) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(url, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m url\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to fetch schema from non-file URL: http://stsci.edu/schemas/jwst_datamodel/level1b.schema"
     ]
    }
   ],
   "source": [
    "# run first step of the pipeline - should be same for nircam and nirspec\n",
    "# copied from Jane/Jared's notebook on nircam reductions\n",
    "files = glob.glob(input_path + '*nrs*/*_uncal.fits') #list the uncalibrated (level 1b) files.\n",
    "files = sorted(files)\n",
    "for exposure in files:\n",
    "    Detector1Pipeline.call(exposure,#config_file=detector1_parameter_file, maximum_cores=5,\\\n",
    "                           output_dir=output_path + 'L2a/',\\\n",
    "                           output_file=f'{os.path.basename(exposure)[:-11]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df98a7b",
   "metadata": {},
   "source": [
    "The above block works to run the pipeline with default parameters. To control parameters directly from the notebook, the below version (should) work. Simply add \"det1.[step].[param] = [val]\" before calling \"det1(exposure)\"\n",
    "For example, to utilize multiple cores, add the line \"det1.jump.maximum_cores = 'half'\" and \"det1.ramp_fit.maximum_cores = 'half'\" to use half the available cores in those two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ebc01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# different version running the Stage 1 pipeline w/ more (easier) control\n",
    "# using the run method allows more flexibility than the call method for some odd reason\n",
    "files_27 = glob.glob(input_path + 'jw01355027*/*_uncal.fits') #list the uncalibrated (level 1b) files.\n",
    "files_27 = sorted(files_27)\n",
    "for exposure in files_27:\n",
    "    det1 = Detector1Pipeline()\n",
    "    det1.output_dir = output_path + 'L2a/obs27/'\n",
    "    det1.save_results = True\n",
    "    det1.save_parameters = True\n",
    "    det1.jump.maximum_cores = 'half'\n",
    "    det1.ramp_fit.maximum_cores = 'half'\n",
    "    det1(exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a791f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# and again for the obs28 files (which should be the background exposures)\n",
    "files_28 = glob.glob(input_path + 'jw01355028*/*_uncal.fits') #list the uncalibrated (level 1b) files.\n",
    "files_28 = sorted(files_28)\n",
    "for exposure in files_28:\n",
    "    det1 = Detector1Pipeline()\n",
    "    det1.output_dir = output_path + 'L2a/obs28/'\n",
    "    det1.save_results = True\n",
    "    det1.save_parameters = True\n",
    "    det1.jump.maximum_cores = 'half'\n",
    "    det1.ramp_fit.maximum_cores = 'half'\n",
    "    #det1(exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f9db5",
   "metadata": {},
   "source": [
    "## Stage 2 - Produce calibrated exposures\n",
    "As mentioned above, these next two cells assume that you have two directories with the L2a outputs from the Stage 1 pipeline. Currently I'm calling these \"obs27\" and \"obs28\", as they are labelled in the uncal.fits file names. \"obs27\" is the science target, and \"obs28\" is the background target. \n",
    "\n",
    "I split this into two calls, one for the science files (first cell) and one for the background files (second cell). I'm processing them the same way so far, using default pipeline parameters, but that could change in the future. \n",
    "\n",
    "As the pipeline is set up here, no background subtraction is performed in this stage. This version is building toward a \"master\" background subtraction step in the stage 3 pipeline, which will use the \"x1d.fits\" files from the background observations to define a background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156dd69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the second step of the pipeline\n",
    "# So far this will just process each exposure individually\n",
    "\n",
    "files = glob.glob(output_path + 'L2a/obs27/' + '*_rate.fits') #list the rate files.\n",
    "files = sorted(files)\n",
    "for exposure in files:              \n",
    "    Spec2Pipeline.call(exposure,#config_file=image2_parameter_file,\\\n",
    "                        output_dir=output_path + 'L2b/obs27/', \\\n",
    "                        output_file=f'{os.path.basename(exposure)[:-10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96ee7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run L2 pipeline for background observations (28 in current notation)\n",
    "files = glob.glob(output_path + 'L2a/obs28/' + '*_rate.fits') #list the rate files.\n",
    "files = sorted(files)\n",
    "for exposure in files:              \n",
    "    Spec2Pipeline.call(exposure,#config_file=image2_parameter_file,\\\n",
    "                        output_dir=output_path + 'L2b/obs28/', \\\n",
    "                        output_file=f'{os.path.basename(exposure)[:-10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f0c47a",
   "metadata": {},
   "source": [
    "As with Stage 1, I'm adding more code blocks here to call the pipeline a different, more flexible way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a545bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_27 = glob.glob(output_path + 'L2a/obs27/' + '*_rate.fits') #list the rate files.\n",
    "files_27 = sorted(files_27)\n",
    "for exposure in files_27:              \n",
    "    spec2 = Spec2Pipeline()\n",
    "    spec2.output_dir = output_path + 'L2b/obs27/'\n",
    "    spec2.save_parameters = True\n",
    "    spec2.save_results = True\n",
    "    spec2(exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943d115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_28 = glob.glob(output_path + 'L2a/obs28/' + '*_rate.fits') #list the rate files.\n",
    "files_28 = sorted(files_28)\n",
    "for exposure in files_28:              \n",
    "    spec2 = Spec2Pipeline()\n",
    "    spec2.output_dir = output_path + 'L2b/obs28/'\n",
    "    spec2.save_parameters = True\n",
    "    spec2.save_results = True\n",
    "    spec2(exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1754446",
   "metadata": {},
   "source": [
    "## Stage 3 - Creating final data cubes\n",
    "This stage compiles the individual calibrated exposures into a single, (theoretically) science-ready data cube. We first have to define an association file, which tells the pipeline which files to use as science exposures, and which files to use as backgrounds.\n",
    "\n",
    "As mentioned above, for this iteration we are doing a \"master\" background subtraction at this stage. This creates a single 1-D spectrum from an average of the dedicated background exposures (using the extracted 1-D spectra from the previous stage). This averaged spectrum is then universally subtracted from the science data. This type of background subtraction may or may not be the right way to proceed. This is how we find out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BELOW COPIED FROM DAVID LAW'S MIRI MRS NOTEBOOK: \n",
    "# https://github.com/STScI-MIRI/MRS-ExampleNB/blob/main/Flight_Notebook1/MRS_FlightNB1.ipynb\n",
    "# \n",
    "# Define a useful function to write out a Lvl3 association file from an input list\n",
    "# Note that any background exposures have to be of type x1d.\n",
    "def writel3asn(scifiles, bgfiles, asnfile, prodname):\n",
    "    # Define the basic association of science files\n",
    "    asn = afl.asn_from_list(scifiles, rule=DMS_Level3_Base, product_name=prodname)\n",
    "        \n",
    "    # Add background files to the association\n",
    "    if bgfiles:\n",
    "        nbg=len(bgfiles)\n",
    "        for ii in range(0,nbg):\n",
    "            asn['products'][0]['members'].append({'expname': bgfiles[ii], 'exptype': 'background'})\n",
    "        \n",
    "    # Write the association to a json file\n",
    "    _, serialized = asn.dump()\n",
    "    with open(asnfile, 'w') as outfile:\n",
    "        outfile.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make association files - use obs27 for data, obs28 for background\n",
    "calfiles = glob.glob(output_path + 'L2b/obs27/*cal.fits')\n",
    "#calfiles = glob.glob(output_path + 'L2b/obs28/*cal.fits') # testing w/ background images\n",
    "\n",
    "bkgfiles = glob.glob(output_path + 'L2b/obs28/*x1d.fits')\n",
    "\n",
    "asnfile = os.path.join(output_path, 'L3/L3asn.json')\n",
    "#asnfile = os.path.join(output_path, 'L3/bkg/L3bg_asn.json') # testing w/ bkg images\n",
    "\n",
    "writel3asn(calfiles, bkgfiles, asnfile, 'Level3')\n",
    "#writel3asn(calfiles, None, asnfile, 'Level3BG') # testing w/ bkg images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e968d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Next step, call stage 3 pipeline on new asn file\n",
    "asn = os.path.join(output_path, 'L3/L3_asn.json')\n",
    "\n",
    "# setting it up this way (rather than with \"call\") gives a bit more flexibility to edit parameters on the fly\n",
    "spec3 = Spec3Pipeline()\n",
    "spec3.output_dir = output_path + 'L3/'\n",
    "spec3.save_parameters = True\n",
    "spec3.save_results = True # DON'T FORGET THIS OR YOU'LL WASTE SEVERAL HOURS FOR NAUGHT!\n",
    "\n",
    "spec3.run(asn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8000d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e3dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
